{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b81e319-e534-4632-b9f3-15269a4f7a54",
   "metadata": {},
   "source": [
    "## Assignment 6\n",
    "\n",
    "<br>\n",
    "\n",
    "#### Exercise 6.1\n",
    "\n",
    "Consider the dataset from `data_banknote_authentication.csv`.\n",
    "\n",
    "1) Read data into a pandas dataframe.\n",
    "\n",
    "2) Pick the column named \"class\" as target variable `y` and all other columns as feature variables `X`.\n",
    "\n",
    "3) Split the data into training and testing sets with 80/20 ratio and `random_state=20`.\n",
    "\n",
    "4) Use support vector classifier with linear kernel to fit to the training data.\n",
    "\n",
    "5) Predict on the testing data and compute the confusion matrix and classification report.\n",
    "\n",
    "6) Repeat steps 3 and 4 for the radial basis function kernel.\n",
    "\n",
    "7) Compare the two SVM models in your own words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ae61d6-63a6-42ce-b3e8-2e9739cb205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Kernel Results:\n",
      "[[152   2]\n",
      " [  0 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       154\n",
      "           1       0.98      1.00      0.99       121\n",
      "\n",
      "    accuracy                           0.99       275\n",
      "   macro avg       0.99      0.99      0.99       275\n",
      "weighted avg       0.99      0.99      0.99       275\n",
      "\n",
      "RBF Kernel Results:\n",
      "[[154   0]\n",
      " [  0 121]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       154\n",
      "           1       1.00      1.00      1.00       121\n",
      "\n",
      "    accuracy                           1.00       275\n",
      "   macro avg       1.00      1.00      1.00       275\n",
      "weighted avg       1.00      1.00      1.00       275\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"data_banknote_authentication.csv\")\n",
    "\n",
    "\n",
    "X = df.drop(\"class\", axis=1)\n",
    "y = df[\"class\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n",
    "\n",
    "\n",
    "linear_svm = SVC(kernel=\"linear\")\n",
    "linear_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_linear = linear_svm.predict(X_test)\n",
    "print(\"Linear Kernel Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_linear))\n",
    "print(classification_report(y_test, y_pred_linear))\n",
    "\n",
    "\n",
    "rbf_svm = SVC(kernel=\"rbf\")\n",
    "rbf_svm.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_pred_rbf = rbf_svm.predict(X_test)\n",
    "print(\"RBF Kernel Results:\")\n",
    "print(confusion_matrix(y_test, y_pred_rbf))\n",
    "print(classification_report(y_test, y_pred_rbf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44f78d3-c457-4b38-903e-b87c7ee70687",
   "metadata": {},
   "outputs": [],
   "source": [
    "The RBF kernel outperformed the linear kernel by achieving perfect classification accuracy, precision, recall, and F1-score, while the linear \n",
    "kernel had a small number of misclassifications, indicating that the RBF model was better at capturing the data’s nonlinear patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bac4ce7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Exercise 6.2\n",
    "\n",
    "This exercise is related to exercise 5.2 of the previous week. Consider the data from CSV file `weight-height.csv`.\n",
    "\n",
    "1) Read data into a pandas dataframe.\n",
    "\n",
    "2) Pick the target variable `y` as weight in kilograms, and the feature variable `X` as height in centimeters.\n",
    "\n",
    "3) Split the data into training and testing sets with 80/20 ratio.\n",
    "\n",
    "4) Scale the training and testing data using normalization and standardization.\n",
    "\n",
    "4) Fit a KNN regression model with `k=5` to the training data without scaling, predict on unscaled testing data and compute the $R^2$ value.\n",
    "\n",
    "6) Repeat step 4 for normalized data.\n",
    "\n",
    "7) Repeat step 4 for standardize data.\n",
    "\n",
    "8) Compare the models in terms of their $R^2$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f80402-3601-4d29-b5ca-60fb4437d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² without scaling: 0.8346485438169171\n",
      "R² with normalization: 0.8346485438169171\n",
      "R² with standardization: 0.8346485438169171\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"weight-height.csv\")  \n",
    "\n",
    "\n",
    "X = df[['Height']]  \n",
    "y = df['Weight']    \n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "minmax = MinMaxScaler()\n",
    "standard = StandardScaler()\n",
    "\n",
    "X_train_norm = minmax.fit_transform(X_train)\n",
    "X_test_norm = minmax.transform(X_test)\n",
    "\n",
    "X_train_std = standard.fit_transform(X_train)\n",
    "X_test_std = standard.transform(X_test)\n",
    "\n",
    "\n",
    "knn_raw = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_raw.fit(X_train, y_train)\n",
    "y_pred_raw = knn_raw.predict(X_test)\n",
    "r2_raw = r2_score(y_test, y_pred_raw)\n",
    "\n",
    "\n",
    "knn_norm = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_norm.fit(X_train_norm, y_train)\n",
    "y_pred_norm = knn_norm.predict(X_test_norm)\n",
    "r2_norm = r2_score(y_test, y_pred_norm)\n",
    "\n",
    "\n",
    "knn_std = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_std.fit(X_train_std, y_train)\n",
    "y_pred_std = knn_std.predict(X_test_std)\n",
    "r2_std = r2_score(y_test, y_pred_std)\n",
    "\n",
    "\n",
    "print(\"R² without scaling:\", r2_raw)\n",
    "print(\"R² with normalization:\", r2_norm)\n",
    "print(\"R² with standardization:\", r2_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d9bdc1-18cd-4b45-8579-6b67b26366ff",
   "metadata": {},
   "outputs": [],
   "source": [
    " Conclusion: All three models gave the same R² = 0.8346, showing scaling had no effect with one feature\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
